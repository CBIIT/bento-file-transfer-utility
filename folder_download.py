import os.path
import pickle
import shutil
from google_drive_transfer.download_metrics import Metrics
from file_download import download_file
from google_drive_transfer.folder_inventory import *
from google_drive_transfer.google_authentication import authenticate_service_account
from google_drive_transfer.google_drive_api import *

INVENTORY_KEY = "inventory"
DOWNLOADED_KEY = "downloaded"


def serialize(obj, dump_file):
    """
    Serializes the provided object and writes it to the specified file path
    :param obj: The object to be serialized
    :param dump_file: The file path to which the serialized object is written
    """
    path = os.path.dirname(dump_file)
    if not os.path.exists(path):
        os.makedirs(path)
    dump_file = open(dump_file, 'wb')
    pickle.dump(obj, dump_file, pickle.HIGHEST_PROTOCOL)
    dump_file.close()


def deserialize(folder_id):
    """
    Deserializes an object found at the path 'tmp/<folder_id>.dump.tmp' and then returns the object
    :param folder_id: The folder_id used to identify the object to deserialize
    :return: The deserialized object
    """
    dump_name = os.path.join('tmp', '{}.dump.tmp'.format(folder_id))
    dump_file = open(dump_name, 'rb')
    return pickle.load(dump_file)


def main(inputs):
    # Create service account credentials
    credentials = authenticate_service_account()
    # Create Google Drive API connection using service account credentials
    api = API(credentials)
    # Create an array to store the downloaded files metadata
    downloaded_files = []
    # Loop through each provided Google ID
    for folder_id in inputs.google_id:
        # Create dump file path and create folder structure if necessary
        dump_file = os.path.join('tmp', '{}.dump.tmp'.format(folder_id))
        if os.path.exists(dump_file):
            logging.info("Resuming a previously interrupted transfer")
            serialized_map = deserialize(folder_id)
            inventory = serialized_map[INVENTORY_KEY]
            downloaded_files = serialized_map[DOWNLOADED_KEY]
        else:
            logging.info("Beginning transfer")
            inventory = get_folder_contents(api, folder_id)
        # Initialize and start the download metrics object for the inventory array
        metrics = Metrics(inventory)
        metrics.log_start()
        # Get file metadata array using the current Google ID
        while len(inventory) > 0:
            # Save progress
            serialize({INVENTORY_KEY: inventory, DOWNLOADED_KEY: downloaded_files}, dump_file)
            # Get target file metadata from inventory object
            metadata = inventory.pop()
            # Assemble the full file path and then store the folder path and file name in variables
            download_file(metadata, inputs, api)
            try:
                # Update the metrics object estimate and then retrieve it
                estimate = metrics.update_estimate(metadata[GOOGLE_FILE_SIZE])
                # Print the estimated time remaining generated by the metrics object
                logging.info("Estimated Time Remaining: {}".format(estimate))
            except Exception as ex:
                logging.error(
                    "An error occurred while generating remaining time estimate".format(metadata[GOOGLE_FILE_NAME])
                )
                logging.error(ex)
            downloaded_files.append(metadata)
        # Save empty inventory to signify this folder has completed in case of interruption
        serialize({INVENTORY_KEY: inventory, DOWNLOADED_KEY: downloaded_files}, dump_file)
    # Download has completed so the tmp directory with the progress dump files can be deleted
    shutil.rmtree('tmp')
    # Generate and inventory report from the downloaded files array
    generate_inventory_report(downloaded_files, inputs.output_dir)
    # Print that the transfer has completed
    logging.info("Transfer Completed")


if __name__ == '__main__':
    # Configure logger
    logging.basicConfig(format='%(asctime)s %(levelname)s %(message)s', datefmt='%Y-%m-%d %H:%M:%S', level=logging.INFO)
    # Parse and verify command line arguments
    args = parse_arguments()
    if verify_args(args):
        main(args)
